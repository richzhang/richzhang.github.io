
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
        <title>Richard Zhang - UC Berkeley </title>
<style type="text/css"></style></head>
    <body><table border="0" width="980px" align="center"><tbody><tr><td>
    
        </td><td valign="top">
<!--            <img src="images/cmuscslogo.gif">
                <img src="images/rilogo.png"> -->
        <br>
        <table style="font-size: 11pt;" border="0" width="100%">
            <tbody><tr>
                <td width="50%">
                    <!-- <img width="300" src="./index_files/mypic.jpeg" border="0"> -->
                    <img width="300" src="./index_files/mypic2.jpg" border="0">
                </td>
                <td>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="6"> 
                        <b>Richard Zhang</b><br><br>
                    </font>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="4"> 
                        Research Scientist<br>
                        Adobe Research<br>
                        San Francisco, CA<br><br>
                        rizhang at adobe.com<br>
                        [<a href="https://github.com/richzhang" border="0">GitHub</a>]
                        [<a href="https://scholar.google.com/citations?user=LW8ze_UAAAAJ&hl=en" border="0">Google Scholar</a>]
                        [<a href="index_files/CV.pdf" border="0">Resume/CV</a>]<br>
                    </font>
                </td>
            </tr>
        </tbody></table> 
        <p>
        </p><hr size="2" align="left" noshade="">
        <p>
        
        <font face="helvetica, ariel, &#39;sans serif&#39;"> 
        <!--</font></p><h2><font face="helvetica, ariel, &#39;sans serif&#39;">About Me</font></h2><font face="helvetica, ariel, &#39;sans serif&#39;">-->
        I recently joined Adobe Research as a Research Scientist. I was previously a PhD student at UC Berkeley, advised by Professor <a href="http://www.eecs.berkeley.edu/~efros/">Alexei (Alyosha) Efros</a>. I obtained my BS and MEng degrees from Cornell University in ECE. My research interests are in computer vision, machine learning, deep learning, graphics, and image processing.

        <!-- <br><br> -->
        </p><hr size="2" align="left" noshade="">

        <h2>News </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
            <!-- <b>[Jun 2019]</b> <br> -->
            <b>[Jun 2019]</b> See our new work on detecting Photoshopped images below.<br>
            <b>[May 2019]</b> Our work on anti-aliasing convolutional networks has been accepted to ICML 2019. Try anti-aliasing your convnet <a href="https://github.com/adobe/antialiased-cnns">here</a>!<br>
            <b>[Aug 2018]</b> I will be presenting at the Thesis Fast Forward session at SIGGRAPH on Tuesday 8/14, 2:00pm.<br>
            <b>[Jun 2018]</b> We will be presenting our <a href="https://richzhang.github.io/PerceptualSimilarity/">project</a> on perceptual metrics at CVPR, Tuesday 6/19, 10:10am. Try our metric <a href="https://github.com/richzhang/PerceptualSimilarity">here</a>!<br>
            <!-- <b>[May 2018]</b> I have <a href="./index_files/graduation.jpg">graduated</a> from UC Berkeley and have joined Adobe Research as a Research Scientist in San Francisco! -->
            </span>

        </p><hr size="2" align="left" noshade="">

        <h2>Publications </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="15">
				<tbody>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <center>
                        <img width="125" align="center" src="./index_files/aacnns_2019_teaser.gif" border="0">
                        <img width="125" align="center" src="./index_files/aacnns_2019_teaser2.gif" border="0">
                        </center>
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Making Convolutional Networks Shift-Invariant Again</b> <br>
                        <span style="font-size: 10pt;">
                        Richard Zhang. <br>
                        In ICML, 2019. <br>
                        <!-- [<a href="https://richzhang.github.io/antialiased-cnns/resources/camera-ready.pdf">Paper</a>] -->
                        [<a href="https://arxiv.org/abs/1904.11486">Paper</a>]
                        [<a href="https://richzhang.github.io/antialiased-cnns/">Webpage</a>]
                        [<a href="https://github.com/adobe/antialiased-cnns">GitHub</a>]
                        [<a href='https://www.youtube.com/watch?v=HjewNBZz00w&feature=youtu.be'>Talk</a>]
                        [<a href='https://www.dropbox.com/s/771m39a45ygstw9/antialiasing.pptx?dl=0'>Slides</a> (127mb)]
                        [<a href="https://www.dropbox.com/s/dhf2gqt14sq76q7/poster_icml.pdf?dl=0">Poster</a>]
                        [<a href="./index_files/bibtex_icml2019.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <center>
                        <img width="240" align="center" src="./index_files/falteaser.png" border="0">
                        <!-- <img width="125" align="center" src="./index_files/faldetector.gif" border="0"> -->
                        </center>
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Detecting Photoshopped Faces by Scripting Photoshop</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="https://peterwang512.github.io/FALdetector/">Sheng-Yu Wang</a>, <a href="http://www.oliverwang.info/">Oliver Wang</a>, <a href="http://andrewowens.com">Andrew Owens</a>, Richard Zhang, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a> <br>
                        To appear in ICCV, 2019. <br>
                        [<a href="https://arxiv.org/abs/1906.05856">Paper</a>]
                        [<a href="https://peterwang512.github.io/FALdetector/">Webpage</a>]
                        [<a href="https://github.com/peterwang512/FALdetector">GitHub</a>]
                        [<a href="https://www.youtube.com/watch?v=TUootD36Xm0">Video</a>]
                        [<a href="https://theblog.adobe.com/adobe-research-and-uc-berkeley-detecting-facial-manipulations-in-adobe-photoshop/">Adobe Blog</a>]
                        [<a href="./index_files/bibtex_fal2019.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <img width="250" align="center" src="./index_files/shape_2019_teaser.jpg" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Deep Parametric Shape Predictions using Distance Fields</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="http://people.csail.mit.edu/smirnov/">Dmitriy Smirnov</a>,
                        <a href="https://research.adobe.com/person/matt-fisher/">Matthew Fisher</a>,
                        <a href="https://research.adobe.com/person/vladimir-kim/">Vladimir G. Kim</a>,
                        Richard Zhang,
                        <a href="https://people.csail.mit.edu/jsolomon/">Justin Solomon</a><br>
                        In Arxiv, 2019. <br>
                        [<a href="https://arxiv.org/abs/1904.08921">Paper</a>]
                        [<a href="http://people.csail.mit.edu/smirnov/publication/smirnov-deep-2019/">Webpage</a>]
                        [<a href="./index_files/bibtex_arxiv2019_shape.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <img width="250" align="center" src="./index_files/perceptual_teaser.jpg" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>The Unreasonable Effectiveness of Deep Features as a Perceptual Metric</b> <br>
                        <span style="font-size: 10pt;">
                        Richard Zhang, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, 
                        <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>, <a href="http://www.oliverwang.info/">Oliver Wang</a><br>
                        In CVPR, 2018. <br>
                        [<a href="http://arxiv.org/abs/1801.03924">Paper</a>]
                        [<a href="https://richzhang.github.io/PerceptualSimilarity/">Webpage</a>]
                        [<a href="https://github.com/richzhang/PerceptualSimilarity">GitHub</a>]
                        [<a href="https://richzhang.github.io/PerceptualSimilarity/index_files/poster_cvpr.pdf">Poster</a>]
                        [<a href="https://research.adobe.com/with-deep-learning-computers-see-images-more-like-humans-do/">Adobe Blog</a>]
                        [<a href="https://www.youtube.com/watch?v=DglrYx9F3UU">Two Min Papers</a>]
                        [<a href="./index_files/bibtex_cvpr2018.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <img width="250" align="center" src="./index_files/savp3.gif" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Stochastic Adversarial Video Prediction</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="http://people.eecs.berkeley.edu/~alexlee_gk/index.html">Alex X. Lee</a>, Richard Zhang, 
                        <a href="https://febert.github.io/">Frederik Ebert</a>, <a href="http://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>, <a href="https://people.eecs.berkeley.edu/~cbfinn/">Chelsea Finn</a>, <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a> <br>
                        In ArXiv, 2018. <br>
                        [<a href="https://arxiv.org/abs/1804.01523">Paper</a>]
                        [<a href="https://alexlee-gk.github.io/video_prediction/">Webpage</a>]
                        [<a href="https://github.com/alexlee-gk/video_prediction">GitHub</a>]
                        [<a href="./index_files/bibtex_savp.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <img width="250" align="center" src="./index_files/nips2017.jpg" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Toward Multimodal Image-to-Image Translation</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu</a>, Richard Zhang, <a href="http://people.eecs.berkeley.edu/~pathak/">Deepak Pathak</a>, <a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, <a href="http://www.oliverwang.info/">Oliver Wang</a>, 
                        <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a> <br>
                        In NIPS, 2017. <br>
                        [<a href="https://arxiv.org/abs/1711.11586">Paper</a>]
                        <!-- <a href="https://papers.nips.cc/paper/6650-toward-multimodal-image-to-image-translation">Official</a>] -->
                        [<a href="https://junyanz.github.io/BicycleGAN/">Webpage</a>]
                        [<a href="https://github.com/junyanz/BicycleGAN">GitHub</a>]
                        [Video (<a href="https://www.youtube.com/watch?v=JvGysD2EFhw">YouTube</a>)(<a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN/video_extended.mp4">mp4</a>)]
                        [<a href="http://junyanz.github.io/BicycleGAN/index_files/poster_nips_v3.pdf">Poster</a>]
                        [<a href="https://www.youtube.com/watch?v=XcxzKLrCpyk">Two Min Papers</a>]
                        [<a href="./index_files/bibtex_nips2017.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <a href="http://richzhang.github.io/ideepcolor"><img width="250" align="center" src="./index_files/siggraph2017_update.jpg" border="0"></a>
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Real-Time User-Guided Image Colorization with Learned Deep Priors</b> <br>
                        <span style="font-size: 10pt;">
                        Richard Zhang*, <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu</a>*, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, <a href="http://young-geng.xyz/">Xinyang Geng</a>, Angela S. Lin, Tianhe Yu, 
                        <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>        <br>
                        (*indicates equal contribution) <br>
                        In SIGGRAPH, 2017. <br>
                        [<a href="https://arxiv.org/abs/1705.02999">Paper</a>]
                        <!-- <a href="https://dl.acm.org/citation.cfm?id=3073703">Official</a>] -->
                        [<a href="https://richzhang.github.io/ideepcolor/">Webpage</a>]
                        [<a href="https://youtu.be/eiFzQI7LzO0?t=5690">Fastforward</a>]
                        [<a href="https://www.youtube.com/watch?v=rp5LUSbdsys">Talk</a>]
                        [Video (<a href="https://www.youtube.com/watch?v=eL5ilZgM89Q&feature=youtu.be">YouTube</a>)(<a href="https://www.dropbox.com/s/mfi66auuv7qzyx0/iColor_release.mp4?dl=0">mp4</a>)]
                        [<a href="https://github.com/junyanz/interactive-deep-colorization">GitHub</a>]
                        [<a href="https://www.dropbox.com/s/urmifx558nw0ogi/release.pptx?dl=0">Slides</a> (141mb)]
                        [<a href="./index_files/bibtex_siggraph2017.txt">Bibtex</a>]
                        <br>

                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                        <a href="http://richzhang.github.io/splitbrainauto"><img width="250" align="center" src="./index_files/cvpr2017_splitbrain.png" border="0"></a>
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction</b><br>
                        <span style="font-size: 10pt;">
                        Richard Zhang, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>,
                        <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>        <br>
                        In CVPR, 2017.
                        <br>
                        [<a href="https://arxiv.org/abs/1611.09842">Paper</a>]
                        <!-- (<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Zhang_Split-Brain_Autoencoders_Unsupervised_CVPR_2017_paper.html">official</a>)] -->
                        [<a href="http://richzhang.github.io/splitbrainauto">Webpage</a>]
                        [<a href="https://github.com/richzhang/splitbrainauto">GitHub</a>]
                        [<a href="https://richzhang.github.io/splitbrainauto/index_files/poster_cvpr.pdf">Poster</a>]
                        [<a href="https://www.youtube.com/watch?v=FTzcFsz2xqw">Seminar Talk</a>]
                        [<a href="./index_files/bibtex_cvpr2017_splitbrain.txt">Bibtex</a>]</span>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="90" -->
                        <a href="http://richzhang.github.io/colorization/"><img width="250" align="center" src="./index_files/arxiv2016_colorization.jpg" border="0"></a>
                        </td>
                        <td>
                        <span style="font-size: 12pt;"><b>Colorful Image Colorization</span></b><br>
                        <span style="font-size: 10pt;">
                        Richard Zhang, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>,
                        <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>        <br>
                        In ECCV, 2016 (oral presentation).
                        <br>
                        [<a href="https://arxiv.org/abs/1603.08511">Paper</a>]
                        <!-- <a href="https://link.springer.com/chapter/10.1007/978-3-319-46487-9_40">Official</a>] -->
                        [<a href="http://richzhang.github.io/colorization/">Webpage</a>]
                        [<a href="https://github.com/richzhang/colorization">GitHub</a>]
                        [<a href="http://videolectures.net/eccv2016_zhang_image_colorization/">Talk</a>]
                        [<a href="https://www.dropbox.com/s/sa8m3y1ymj0ihct/presentation_eccv_release.pptx?dl=0">Slides</a> (138mb)]
                        [<a href="http://www.eccv2016.org/files/posters/O-2B-03.pdf">Poster</a>]
                        [<a href="./index_files/bibtex_eccv2016_colorization.txt">Bibtex</a>]
                    </td>
                </tr>
                <tr>

					<td width="30%" align=left>
						<img width="250" align="center" src="./index_files/icra2015.png" border="0">
                    </td>
					<td>
                        <span style="font-size: 12pt;">
                        <b>Sensor Fusion for Semantic Segmentation of Urban Scenes</b><br>
                        <span style="font-size: 10pt;"> 
						Richard Zhang, Stefan Candra, </a><a href="http://anp.lbl.gov/kai-vetter/">Kai Vetter</a>,
                        <a href="http://www-video.eecs.berkeley.edu/~avz/">Avideh Zakhor</a>		<br>
						In ICRA, 2015.
                        <br>
                        [Paper (<a href="./index_files/icra2015.pdf">pdf</a>)(<a href="http://ieeexplore.ieee.org/document/7139439/">official</a>)]

                        [<a href="./index_files/pres_icra2015.pdf">Slides</a>]
                        [<a href="./index_files/poster_icra2015.pdf">Poster</a>]
                        [<a href="https://www.youtube.com/watch?v=s9X63Ma3M0Y">Talk</a>]

                        [Annotations (<a href="http://www.eecs.berkeley.edu/~rich.zhang/projects/2015_ICRA_semanticsegmentation/KITTI_public.tar">tar</a>)(<a href="http://www.eecs.berkeley.edu/~rich.zhang/projects/2015_ICRA_semanticsegmentation/KITTI_public.zip">zip</a>) ]
                        [<a href="./index_files/bibtex_icra2015.txt">Bibtex</a>]
                        </span>
					</td>
				</tr>  
                <tr>
                    <td width="30%" align="center">
                    <!-- height="100" -->
                        <img height="95" horizontal-align="center" src="./index_files/wacv2014.png" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;"><b>Automatic Identification of Window Regions on Indoor Point Clouds Using LiDAR and Cameras</b><br>
                        <span style="font-size: 10pt;">
                        Richard Zhang,
                        <a href="http://www-video.eecs.berkeley.edu/~avz/">Avideh Zakhor</a>
                        <br>
                        In WACV, 2014.
                        <br>
                        [Paper (<a href="./index_files/wacv2014.pdf">pdf</a>)(<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.649.303&rep=rep1&type=pdf">official</a>)]

                        [<a href="./index_files/bibtex_wacv2014.txt">Bibtex</a>]
                        </span>
                    </td>
                </tr>

            </tbody></table>

        <h2>Thesis </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="15">
                <tbody>
                <tr>
                    <td width="30%" align=left>
                        <img width="250" align="center" src="./index_files/berkeley_logo.png" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Image Synthesis for Self-Supervised Visual Representation Learning</b> <br>
                        <span style="font-size: 10pt;">
                        Richard Zhang<br>
                        <!-- Commitee: Alexei A. Efros, Trevor Darrell, Michael DeWeese.<br> -->
                        Spring 2018.<br>
                        [<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-36.html">Thesis</a>]
                        [<a href="https://www.youtube.com/watch?v=aGhYitrOJRc">Dissertation Talk</a>]
                        [<a href="https://youtu.be/IXG-uWFAkmM">Fast Forward</a>]
                        [<a href="https://www.dropbox.com/s/96f0xhfwvjnbf52/presentation_dissertation.pptx?dl=0">Slides</a> (396 MB)]
                        [<a href="./index_files/bibtex_thesis.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
            </tbody></table>

        <h2>Teaching </h2>
        <!-- <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017 -->
        <span style="font-size: 12pt;">
        <b>Introduction to Artificial Intelligence (CS 188)</b>, UC Berkeley <br>
        <span style="font-size: 10pt;">
        Graduate Student Instructor (GSI) with Prof. <a href="http://people.eecs.berkeley.edu/~anca/">Anca Dragan</a> <br>
        Spring 2017<br>
        <br>
        <span style="font-size: 12pt;">
        <b>Computer Vision (CS 280)</b>, UC Berkeley <br>
        <span style="font-size: 10pt;">
        Graduate Student Instructor (GSI) with Prof. <a href="http://people.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, Prof. <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a> <br>
        Spring 2016<br>
        <br>
        <span style="font-size: 12pt;">
        <b>Introduction to Circuits (ECE 2100)</b>, Cornell University <br>
        <span style="font-size: 10pt;">
        Teaching Assistant (TA) with Prof. <a href="https://molnargroup.ece.cornell.edu/">Alyosha Molnar</a> <br>
        Spring 2010<br>
        <br>

        <h2>Awards </h2>
        <span style="font-size: 10pt;">
        Thesis Fast Forward, Best Presentation, SIGGRAPH 2018<br>
        <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017
        </span><br>
<!--         <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="25">
                <tbody>
                <tr>
                    <td width="30%" align="center">
                        <img height="75" horizontal-align="center" src="./index_files/Adobe-logo.png" border="0">
                            </td>
                    <td>
                        <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017
                    </td>
                </tr>
            </tbody></table>
        </font> -->

        <br>

        <h2>Collaborators</h2>
        I have had the opportunity to work with some wonderful collaborators.
        <p>
          
        <!--
        <dl class="dl-horizontal">
          <dt>Current Undergrads</dt>
        </dl>
        -->
        <!-- <dl class="dl-horizontal"> -->
            <dt><b>Doctoral Researchers</b></dt>
            <a href="http://arnabgho.github.io/">Arnab Ghosh</a>, from Oxford<br>
            <a href="http://people.csail.mit.edu/smirnov/">Dima Smirnov</a>, from MIT<br>
            <!-- <a href="https://www.cs.tau.ac.il/~noafish/">Noa Fish</a>, from Tel Aviv<br> -->
            <!-- <a href="http://alvinwan.com/">Alvin Wan</a>, from UC Berkeley<br> -->

            <br>

            <dt><b>Undergraduate/Masters Researchers</b></dt>
            <a href="http://peterwang512.github.io/">Sheng-Yu Wang</a> <br>
            <a href="https://www.linkedin.com/in/xin-qin-4a83b9158/">Xin Qin</a>, now @ USC <br>
            <a href="https://www.linkedin.com/in/hemangjangle/">Hemang Jangle</a> <br>
            <a href="http://www.cs.utexas.edu/~alin/">Angela S. Lin</a>, now @ UT Austin <br>
            <a href="http://young-geng.xyz/">Xinyang Geng</a>, now @ UC Berkeley<br>
            <a href="https://tianheyu927.github.io/">Tianhe Yu</a>, now @ Stanford<br>
            <a href="https://www.linkedin.com/in/candrastefan/">Stefan A. Candra</a><br>
        <!-- </dl> -->
        </p>


<!--         <h2>Internship </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
            If you have similar interests and are interested in collaborating during a summer 2020 internship, feel free to contact me. Please tell me about your past research experience and what you would potentially like to do. The goal of an internship is a publication, typically CVPR or SIGGRAPH (see my two most recent publications, which were from my summer 2017 internship). Interns are typically PhD students. The number of slots is limited, so we unfortunately cannot accept everyone.
            </span>
        </p><hr size="2" align="left" noshade=""> -->


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75897335-1', 'auto');
  ga('send', 'pageview');
</script>
            
</font></td></tr></tbody></table><iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" input="null" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div></body></html>

