
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252" charset="utf-8">
        <title>Richard Zhang - Research Scientist, Adobe Research </title>
<style type="text/css"></style></head>
    <body><table border="0" width="980px" align="center"><tbody><tr><td>
    
        </td><td valign="top">
<!--            <img src="images/cmuscslogo.gif">
                <img src="images/rilogo.png"> -->
        <br>
        <table style="font-size: 11pt;" border="0" width="100%">
            <tbody><tr>
                <td width="50%">
                    <!-- <img width="300" src="./index_files/mypic.jpeg" border="0"> -->
                    <!-- <img width="300" src="./index_files/mypic2.jpg" border="0"> -->
                    <img width="250" src="./index_files/mypic3.jpg" border="0">
                </td>
                <td>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="6"> 
                        <b>Richard Zhang</b><br><br>
                    </font>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="4"> 
                        Research Scientist<br>
                        Adobe Research<br>
                        San Francisco, CA<br><br>
                        rizhang at adobe.com<br>
                        [<a href="https://github.com/richzhang" border="0">GitHub</a>]
                        [<a href="https://scholar.google.com/citations?user=LW8ze_UAAAAJ&hl=en" border="0">Google Scholar</a>]
                        [<a href="index_files/CV.pdf" border="0">Resume/CV</a>]<br>
                    </font>
                </td>
            </tr>
        </tbody></table> 
        <p>
        </p><hr size="2" align="left" noshade="">
        <p>
        
        <font face="helvetica, ariel, &#39;sans serif&#39;"> 
        <!--</font></p><h2><font face="helvetica, ariel, &#39;sans serif&#39;">About Me</font></h2><font face="helvetica, ariel, &#39;sans serif&#39;">-->
        My research interests are in computer vision, machine learning, deep learning, graphics, and image processing. I obtained a PhD at UC Berkeley, advised by Prof. <a href="http://www.eecs.berkeley.edu/~efros/">Alexei (Alyosha) Efros</a>. I obtained BS and MEng degrees from Cornell University in ECE. I often collaborate with academic researchers, either through internships or university collaboration.

        <!-- <br><br> -->
        </p><hr size="2" align="left" noshade="">

        <h3>News </h3>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
            <!-- <b>[Jun 2019]</b> <br> -->
            <b>[Feb 2020]</b> I served as an Area Chair for CVPR 2020 and spoke on <a href="https://www.youtube.com/watch?v=aNDwHRxWTa0">Analyzing CNN Artifacts in Discriminative and Generative Models</a> (11 min). The second half includes our "Detecting CNN-generated images" work, just accepted to CVPR.<br>
            <b>[Dec 2019]</b> See our new work on detecting CNN-generated images below.<br>
            <b>[Nov 2019]</b> I presented our "Detecting Photoshop" ICCV19 work at <a href="https://www.youtube.com/watch?v=21lj8tCSMkg">Adobe MAX</a> (5 min), on stage with John Mulaney (aka Peter Porker/Spider-Ham)!<br>
            <b>[Oct 2019]</b> Thank you <a href="https://twitter.com/Oxford_VGG/status/1184087868857290752">Oxford</a> and UCL for hosting me.<br>
            <b>[Oct 2019]</b> This <a href="http://video.tv.adobe.com/v/28291">video</a> shows interactive colorization in Photoshop Elements 2020, based on our SIGGRAPH 2017 work.<br>
            <b>[Sept 2019]</b> See our new work on interactive sketch to image synthesis below.<br>
            <b>[Jun 2019]</b> See our new work on detecting Photoshopped images below.<br>
            <b>[May 2019]</b> Our work on anti-aliasing convolutional networks has been accepted to ICML 2019. Try anti-aliasing your convnet <a href="https://github.com/adobe/antialiased-cnns">here</a>!<br>
            <!-- <b>[Aug 2018]</b> I will be presenting at the Thesis Fast Forward session at SIGGRAPH on Tuesday 8/14, 2:00pm.<br> -->
            <!-- <b>[Jun 2018]</b> We will be presenting our <a href="https://richzhang.github.io/PerceptualSimilarity/">project</a> on perceptual metrics at CVPR, Tuesday 6/19, 10:10am. Try our metric <a href="https://github.com/richzhang/PerceptualSimilarity">here</a>!<br> -->
            <!-- <b>[May 2018]</b> I have <a href="./index_files/graduation.jpg">graduated</a> from UC Berkeley and have joined Adobe Research as a Research Scientist in San Francisco! -->
            </span>

        </p><hr size="2" align="left" noshade="">

<!--         <h3>Internship </h3>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
            If you have similar interests and are interested in collaborating during a summer 2020 internship, please feel free to contact me! Tell me about your past research experience and what you would potentially like to do. The goal of an internship is a publication, usually CVPR or SIGGRAPH. For example, see my NIPS 2017 and CVPR 2018 papers, which were from my summer 2017 internship. Interns are typically PhD students. The number of slots is limited, so we unfortunately cannot accept everyone.
            </span>
        </font>

        </p><hr size="2" align="left" noshade="">
 -->
        <h2>Publications </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="15">
				<tbody>

                <tr>
                    <td width="30%" align=center>
                    <!-- height="74" -->
                        <!-- <center> -->
                        <img width="220" align="center" src="./index_files/cnndetect_teaser2.png" border="0">
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>CNN-generated images are surprisingly easy to spot...for now</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="https://peterwang512.github.io">Sheng-Yu Wang</a>, <a href="http://www.oliverwang.info/">Oliver Wang</a>, Richard Zhang, <a href="http://andrewowens.com">Andrew Owens</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a> <br>
                        To appear in CVPR, 2020 (oral). <br>
                        [<a href="https://arxiv.org/abs/1912.11035">Paper</a>]
                        [<a href="https://peterwang512.github.io/CNNDetection/">Webpage</a>]
                        [<a href="https://github.com/PeterWang512/CNNDetection">GitHub</a>]
                        [<a href="https://youtu.be/aNDwHRxWTa0?t=343">Workshop Talk</a>]
                        [<a href="https://peterwang512.github.io/CNNDetection/bibtex.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <img width="250" align="center" src="./index_files/shape_2019_teaser.jpg" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Deep Parametric Shape Predictions using Distance Fields</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="http://people.csail.mit.edu/smirnov/">Dmitriy Smirnov</a>,
                        <a href="https://research.adobe.com/person/matt-fisher/">Matthew Fisher</a>,
                        <a href="https://research.adobe.com/person/vladimir-kim/">Vladimir G. Kim</a>,
                        Richard Zhang,
                        <a href="https://people.csail.mit.edu/jsolomon/">Justin Solomon</a><br>
                        To appear in CVPR, 2020. <br>
                        [<a href="https://arxiv.org/abs/1904.08921">Paper</a>]
                        [<a href="https://people.csail.mit.edu/smirnov/deep-parametric-shapes/">Webpage</a>]
                        [<a href="https://github.com/dmsm/DeepParametricShapes">GitHub</a>]
                        [<a href="https://www.youtube.com/watch?v=v_0UrjbTtHg">Video</a>]
                        [<a href="./index_files/bibtex_arxiv2019_shape.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <!-- <center> -->
                        <div style="width: 260; height: 80; margin: -10px 0px 0px 0px; overflow: hidden">
                            <img width="75" align="center" src="./index_files/morph_1028_AB.jpg_100619_AB.jpg.gif" border="0">
                            <img width="75" align="center" src="./index_files/morph_7994928.362576.jpg_7590611.3.jpg.gif" border="0">
                            <img width="100" align="center" src="./index_files/morph_3113.png_3938.png.gif" border="0">
                        </div>
                        <!-- <img width="80" align="center" src="./index_files/morph_100938_AB.jpg_27721_AB.jpg.gif" border="0"> -->
                        <!-- <img width="80" align="center" src="./index_files/morph_f58a26c915e7a1dceae7a0fa074b4a2a_1.png_7805239ad1e40e07c69d7040c52664c5_1.png.gif" border="0"> -->
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b> Image Morphing with Perceptual Constraints and STN Alignment </b> <br>
                        <span style="font-size: 10pt;">
                        <a href="https://www.cs.tau.ac.il/~noafish/">Noa Fish</a>, Richard Zhang, Lilach Perry, <a href="https://www.cs.tau.ac.il/~dcor/index.html">Daniel Cohen-Or</a>, <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>, <a href="http://www.connellybarnes.com/">Connelly Barnes</a><br>
                        To appear in CGF, 2020. <br>
                        [<a href="https://arxiv.org/abs/2004.14071">Paper</a>]
                        [<a href="./index_files/bibtex_arxiv2020_morph.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>


                <tr>
                    <td width="30%" align=left>
                        <img width="260" align="center" src="./index_files/arxiv2020_project_teaser.jpg" border="0">
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b> Transforming and Projecting Images into Class-conditional Generative Networks</b><br>
                        <span style="font-size: 10pt;">
                        <a href="http://people.csail.mit.edu/minhuh/">Minyoung Huh</a>, Richard Zhang, <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu</a>, <a href="http://people.csail.mit.edu/sparis/">Sylvain Paris</a>, <a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a><br>
                        In ArXiv, 2020. <br>
                        <!-- [<a href="">Paper</a>] -->
                        [<a href="https://arxiv.org/abs/2005.01703">Paper</a>]
                        [<a href="https://minyoungg.github.io/GAN-Transform-and-Project/">Webpage</a>]
                        [<a href="https://github.com/minyoungg/GAN-Transform-and-Project">Code</a>]
                        [<a href="./index_files/bibtex_arxiv2020_trans_proj.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <!-- <center> -->
                        <img width="260" align="center" src="./index_files/audio_teaser.jpg" border="0">
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>A Differentiable Perceptual Audio Metric Learned from Just Noticeable Differences</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="https://www.cs.princeton.edu/~pmanocha/">Pranay Manocha</a>, <a href="https://www.cs.princeton.edu/~af/">Adam Finkelstein</a>, Richard Zhang, <a href="https://ccrma.stanford.edu/~njb/">Nicholas J. Bryan</a>, <a href="https://ccrma.stanford.edu/~gautham/Site/Gautham_J._Mysore.html">Gautham J. Mysore</a>, <a href="https://research.adobe.com/person/zeyu-jin/">Zeyu Jin</a><br>
                        In ArXiv, 2020. <br>
                        [<a href="https://arxiv.org/abs/2001.04460">Paper</a>]
                        [<a href="https://gfx.cs.princeton.edu/pubs/Manocha_2020_ADP/">Webpage</a>]
                        [<a href="https://github.com/pranaymanocha/PerceptualAudio">GitHub</a>]
                        [<a href="./index_files/bibtex_arxiv2020_audio.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <!-- <center> -->
                        <img width="125" align="center" src="./index_files/aacnns_2019_teaser.gif" border="0">
                        <img width="125" align="center" src="./index_files/aacnns_2019_teaser2.gif" border="0">
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Making Convolutional Networks Shift-Invariant Again</b> <br>
                        <span style="font-size: 10pt;">
                        Richard Zhang <br>
                        In ICML, 2019. <br>
                        <!-- [<a href="https://richzhang.github.io/antialiased-cnns/resources/camera-ready.pdf">Paper</a>] -->
                        [<a href="https://arxiv.org/abs/1904.11486">Paper</a>]
                        [<a href="https://richzhang.github.io/antialiased-cnns/">Webpage</a>]
                        [<a href="https://github.com/adobe/antialiased-cnns">GitHub</a>]
                        [<a href='https://www.youtube.com/watch?v=HjewNBZz00w&feature=youtu.be'>Talk</a>]
                        [<a href='https://www.dropbox.com/s/bzo8kia5si811tm/antialiasing_bair.pptx?dl=0'>Slides</a> (122mb)]
                        [<a href="https://www.dropbox.com/s/dhf2gqt14sq76q7/poster_icml.pdf?dl=0">Poster</a>]
                        [<a href="./index_files/bibtex_icml2019.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <!-- <center> -->
                        <img width="250" align="center" src="./index_files/falteaser.png" border="0">
                        <!-- </center> -->
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Detecting Photoshopped Faces by Scripting Photoshop</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="https://peterwang512.github.io/">Sheng-Yu Wang</a>, <a href="http://www.oliverwang.info/">Oliver Wang</a>, <a href="http://andrewowens.com">Andrew Owens</a>, Richard Zhang, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a> <br>
                        In ICCV, 2019. <br>
                        [<a href="https://arxiv.org/abs/1906.05856">Paper</a>]
                        [<a href="https://peterwang512.github.io/FALdetector/">Webpage</a>]
                        [<a href="https://github.com/peterwang512/FALdetector">GitHub</a>]
                        [<a href="https://www.youtube.com/watch?v=TUootD36Xm0">Video</a>]
                        [<a href="https://www.dropbox.com/s/qn4c19134zjziyi/%5BFinal%5D%20ICCV%20Poster.pdf?dl=0">Poster</a>]
                        [<a href="https://www.youtube.com/watch?v=21lj8tCSMkg">Adobe Max</a>]
                        [<a href="https://theblog.adobe.com/adobe-research-and-uc-berkeley-detecting-facial-manipulations-in-adobe-photoshop/">Adobe Blog</a>]
                        [<a href="./index_files/bibtex_fal2019.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <img width="125" align="center" src="./index_files/isketchnfill_teaser.gif" border="0">
                        <img width="125" align="center" src="./index_files/isketchnfill_teaser2.gif" border="0">
                    </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Interactive Sketch & Fill: Multiclass Sketch-to-Image Translation</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="https://arnabgho.github.io/">Arnab Ghosh</a>,
                        Richard Zhang,
                        <a href="https://puneetkdokania.github.io/">Puneet Dokania</a>,
                        <a href="http://www.oliverwang.info/">Oliver Wang</a>,
                        <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>,
                        <a href="http://www.robots.ox.ac.uk/~phst/">Philip H.S. Torr</a>,
                        <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>
                        In ICCV, 2019. <br>
                        [<a href="https://arxiv.org/abs/1909.11081">Paper</a>]
                        [<a href="https://arnabgho.github.io/iSketchNFill/">Webpage</a>]
                        [<a href="https://github.com/arnabgho/iSketchNFill">GitHub</a>]
                        [<a href="https://www.youtube.com/watch?v=T9xtpAMUDps">Video</a>]
                        [<a href="./index_files/bibtex_iccv2019_isketchnfill.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>

                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <img width="250" align="center" src="./index_files/perceptual_teaser.jpg" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>The Unreasonable Effectiveness of Deep Features as a Perceptual Metric</b> <br>
                        <span style="font-size: 10pt;">
                        Richard Zhang, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, 
                        <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>, <a href="http://www.oliverwang.info/">Oliver Wang</a><br>
                        In CVPR, 2018. <br>
                        [<a href="http://arxiv.org/abs/1801.03924">Paper</a>]
                        [<a href="https://richzhang.github.io/PerceptualSimilarity/">Webpage</a>]
                        [<a href="https://github.com/richzhang/PerceptualSimilarity">GitHub</a>]
                        [<a href="https://richzhang.github.io/PerceptualSimilarity/index_files/poster_cvpr.pdf">Poster</a>]
                        [<a href="https://research.adobe.com/with-deep-learning-computers-see-images-more-like-humans-do/">Adobe Blog</a>]
                        [<a href="https://www.youtube.com/watch?v=DglrYx9F3UU">Two Min Papers</a>]
                        [<a href="./index_files/bibtex_cvpr2018.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <img width="250" align="center" src="./index_files/savp3.gif" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Stochastic Adversarial Video Prediction</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="http://people.eecs.berkeley.edu/~alexlee_gk/index.html">Alex X. Lee</a>, Richard Zhang, 
                        <a href="https://febert.github.io/">Frederik Ebert</a>, <a href="http://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>, <a href="https://people.eecs.berkeley.edu/~cbfinn/">Chelsea Finn</a>, <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a> <br>
                        In ArXiv, 2018. <br>
                        [<a href="https://arxiv.org/abs/1804.01523">Paper</a>]
                        [<a href="https://alexlee-gk.github.io/video_prediction/">Webpage</a>]
                        [<a href="https://github.com/alexlee-gk/video_prediction">GitHub</a>]
                        [<a href="./index_files/bibtex_savp.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <img width="250" align="center" src="./index_files/nips2017.jpg" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Toward Multimodal Image-to-Image Translation</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu</a>, Richard Zhang, <a href="http://people.eecs.berkeley.edu/~pathak/">Deepak Pathak</a>, <a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, <a href="http://www.oliverwang.info/">Oliver Wang</a>, 
                        <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a> <br>
                        In NIPS, 2017. <br>
                        [<a href="https://arxiv.org/abs/1711.11586">Paper</a>]
                        <!-- <a href="https://papers.nips.cc/paper/6650-toward-multimodal-image-to-image-translation">Official</a>] -->
                        [<a href="https://junyanz.github.io/BicycleGAN/">Webpage</a>]
                        [<a href="https://github.com/junyanz/BicycleGAN">GitHub</a>]
                        [Video (<a href="https://www.youtube.com/watch?v=JvGysD2EFhw">YouTube</a>)(<a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN/video_extended.mp4">mp4</a>)]
                        [<a href="http://junyanz.github.io/BicycleGAN/index_files/poster_nips_v3.pdf">Poster</a>]
                        [<a href="https://www.youtube.com/watch?v=XcxzKLrCpyk">Two Min Papers</a>]
                        [<a href="./index_files/bibtex_nips2017.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <a href="http://richzhang.github.io/ideepcolor"><img width="250" align="center" src="./index_files/siggraph2017_update.jpg" border="0"></a>
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Real-Time User-Guided Image Colorization with Learned Deep Priors</b> <br>
                        <span style="font-size: 10pt;">
                        Richard Zhang*, <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu</a>*, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, <a href="http://young-geng.xyz/">Xinyang Geng</a>, <a href="http://www.cs.utexas.edu/~alin/">Angela S. Lin</a>, <a href="https://tianheyu927.github.io/">Tianhe Yu</a>, 
                        <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>        <br>
                        (*indicates equal contribution) <br>
                        In SIGGRAPH, 2017. <br>
                        [<a href="https://arxiv.org/abs/1705.02999">Paper</a>]
                        <!-- <a href="https://dl.acm.org/citation.cfm?id=3073703">Official</a>] -->
                        [<a href="https://richzhang.github.io/ideepcolor/">Webpage</a>]
                        [<a href="https://youtu.be/eiFzQI7LzO0?t=5690">Fastforward</a>]
                        [<a href="https://www.youtube.com/watch?v=rp5LUSbdsys">Talk</a>]
                        [Video (<a href="https://www.youtube.com/watch?v=eL5ilZgM89Q&feature=youtu.be">YouTube</a>)(<a href="https://www.dropbox.com/s/mfi66auuv7qzyx0/iColor_release.mp4?dl=0">mp4</a>)]
                        [<a href="http://video.tv.adobe.com/v/28291">PSE 2020</a>]
                        [<a href="https://github.com/junyanz/interactive-deep-colorization">GitHub</a>]
                        [<a href="https://www.dropbox.com/s/urmifx558nw0ogi/release.pptx?dl=0">Slides</a> (141mb)]
                        [<a href="./index_files/bibtex_siggraph2017.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                        <a href="http://richzhang.github.io/splitbrainauto"><img width="250" align="center" src="./index_files/cvpr2017_splitbrain.png" border="0"></a>
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction</b><br>
                        <span style="font-size: 10pt;">
                        Richard Zhang, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>,
                        <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>        <br>
                        In CVPR, 2017.
                        <br>
                        [<a href="https://arxiv.org/abs/1611.09842">Paper</a>]
                        <!-- (<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Zhang_Split-Brain_Autoencoders_Unsupervised_CVPR_2017_paper.html">official</a>)] -->
                        [<a href="http://richzhang.github.io/splitbrainauto">Webpage</a>]
                        [<a href="https://github.com/richzhang/splitbrainauto">GitHub</a>]
                        [<a href="https://richzhang.github.io/splitbrainauto/index_files/poster_cvpr.pdf">Poster</a>]
                        [<a href="https://www.youtube.com/watch?v=FTzcFsz2xqw">Seminar Talk</a>]
                        [<a href="./index_files/bibtex_cvpr2017_splitbrain.txt">Bibtex</a>]</span>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="90" -->
                        <a href="http://richzhang.github.io/colorization/"><img width="250" align="center" src="./index_files/arxiv2016_colorization.jpg" border="0"></a>
                        </td>
                        <td>
                        <span style="font-size: 12pt;"><b>Colorful Image Colorization</span></b><br>
                        <span style="font-size: 10pt;">
                        Richard Zhang, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>,
                        <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>        <br>
                        In ECCV, 2016 (oral).
                        <br>
                        [<a href="https://arxiv.org/abs/1603.08511">Paper</a>]
                        <!-- <a href="https://link.springer.com/chapter/10.1007/978-3-319-46487-9_40">Official</a>] -->
                        [<a href="http://richzhang.github.io/colorization/">Webpage</a>]
                        [<a href="https://github.com/richzhang/colorization">GitHub</a>]
                        [<a href="https://www.youtube.com/watch?v=4xoTD58Wt-0">Talk</a>]
                        [<a href="https://www.dropbox.com/s/sa8m3y1ymj0ihct/presentation_eccv_release.pptx?dl=0">Slides</a> (138mb)]
                        [<a href="http://www.eccv2016.org/files/posters/O-2B-03.pdf">Poster</a>]
                        [<a href="./index_files/bibtex_eccv2016_colorization.txt">Bibtex</a>]
                    </td>
                </tr>
                <tr>

					<td width="30%" align=left>
						<img width="250" align="center" src="./index_files/icra2015.png" border="0">
                    </td>
					<td>
                        <span style="font-size: 12pt;">
                        <b>Sensor Fusion for Semantic Segmentation of Urban Scenes</b><br>
                        <span style="font-size: 10pt;"> 
						Richard Zhang, <a href="https://www.linkedin.com/in/candrastefan/">Stefan Candra</a>, </a><a href="http://anp.lbl.gov/kai-vetter/">Kai Vetter</a>,
                        <a href="http://www-video.eecs.berkeley.edu/~avz/">Avideh Zakhor</a>		<br>
						In ICRA, 2015.
                        <br>
                        [Paper (<a href="./index_files/icra2015.pdf">pdf</a>)(<a href="http://ieeexplore.ieee.org/document/7139439/">official</a>)]

                        [<a href="./index_files/pres_icra2015.pdf">Slides</a>]
                        [<a href="./index_files/poster_icra2015.pdf">Poster</a>]
                        [<a href="https://www.youtube.com/watch?v=s9X63Ma3M0Y">Talk</a>]

                        [Annotations (<a href="http://www.eecs.berkeley.edu/~rich.zhang/projects/2015_ICRA_semanticsegmentation/KITTI_public.tar">tar</a>)(<a href="http://www.eecs.berkeley.edu/~rich.zhang/projects/2015_ICRA_semanticsegmentation/KITTI_public.zip">zip</a>) ]
                        [<a href="./index_files/bibtex_icra2015.txt">Bibtex</a>]
                        </span>
					</td>
				</tr>  
                <tr>
                    <td width="30%" align="center">
                    <!-- height="100" -->
                        <img height="95" horizontal-align="center" src="./index_files/wacv2014.png" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;"><b>Automatic Identification of Window Regions on Indoor Point Clouds Using LiDAR and Cameras</b><br>
                        <span style="font-size: 10pt;">
                        Richard Zhang,
                        <a href="http://www-video.eecs.berkeley.edu/~avz/">Avideh Zakhor</a>
                        <br>
                        In WACV, 2014.
                        <br>
                        [Paper (<a href="./index_files/wacv2014.pdf">pdf</a>)(<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.649.303&rep=rep1&type=pdf">official</a>)]

                        [<a href="./index_files/bibtex_wacv2014.txt">Bibtex</a>]
                        </span>
                    </td>
                </tr>

            </tbody></table>

        <h2>Thesis </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="15">
                <tbody>
                <tr>
                    <td width="30%" align=left>
                        <img width="250" align="center" src="./index_files/berkeley_logo.png" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Image Synthesis for Self-Supervised Visual Representation Learning</b> <br>
                        <span style="font-size: 10pt;">
                        Richard Zhang<br>
                        <!-- Commitee: Alexei A. Efros, Trevor Darrell, Michael DeWeese.<br> -->
                        Spring 2018.<br>
                        [<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-36.html">Thesis</a>]
                        [<a href="https://www.youtube.com/watch?v=aGhYitrOJRc">Dissertation Talk</a>]
                        [<a href="https://youtu.be/IXG-uWFAkmM">Fast Forward</a>]
                        [<a href="https://www.dropbox.com/s/96f0xhfwvjnbf52/presentation_dissertation.pptx?dl=0">Slides</a> (396 MB)]
                        [<a href="./index_files/bibtex_thesis.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
            </tbody></table>

        <h2>Awards </h2>
        <span style="font-size: 10pt;">
        Reviewer recognitions, CVPR 2018, NeurIPS 2019<br>
        Thesis Fast Forward, Best Presentation, SIGGRAPH 2018<br>
        <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017
        </span>
<!--         <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="25">
                <tbody>
                <tr>
                    <td width="30%" align="center">
                        <img height="75" horizontal-align="center" src="./index_files/Adobe-logo.png" border="0">
                            </td>
                    <td>
                        <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017
                    </td>
                </tr>
            </tbody></table>
        </font> -->
        <br>

        <h2>Student collaborators/interns</h2>
        I have had the opportunity to work with some wonderful collaborators.<br>

        <!-- <h3>@Adobe</h3> -->
        <br>
         <span style="font-size: 14pt;">
            <b>@Adobe</b>
        </span>

        <span style="font-size: 10pt;">
        <!-- <p> -->
        <dl class="dl-horizontal">
            <dt><b>PhD [interns]</b></dt>
            <a href="https://taesung.me/">Taesung Park</a>, UC Berkeley (Fellowship winner, 2020)<br>
            <a href="http://arnabgho.github.io/">Arnab Ghosh</a>, Oxford<br>
            <a href="http://minyounghuh.com/">Minyoung (Jacob) Huh</a>, MIT<br>
            <a href="https://stamarot.webgr.technion.ac.il/">Tamar Rott Shaham</a>, Technion (Fellowship winner, 2020)<br>
            <a href="https://payeah.net">Peiye Zhuang</a>, UIUC<br>
            <a href="http://people.csail.mit.edu/smirnov/">Dima Smirnov</a>, MIT<br>
            <a href="https://www.cs.tau.ac.il/~noafish/">Noa Fish</a>, Tel Aviv<br>
            <br>

            <dt><b>Masters [interns]</b></dt>
            <a href="https://sjooyoo.github.io/">Seungjoo Yoo</a>, Korea Univ (WIT scholarship winner, 2019)<br>
            <br>

            <dt><b>PhD [university collaborators]</b></dt>
            <a href="https://www.cs.princeton.edu/~pmanocha/">Pranay Manocha</a>, Princeton<br>
            <a href="https://rawanmg.github.io/">Rawan Alghofaili</a>, George Mason<br>
            <a href="http://alvinwan.com/">Alvin Wan</a>, UC Berkeley<br>
            <br>

            <dt><b>Undergrad [university collaborators]</b></dt>
            <a href="http://peterwang512.github.io/">Sheng-Yu Wang</a>, UC Berkeley <br>

        </dl>

        </span>

        <!-- <h3>@Berkeley</h3> -->
        <!-- <br> -->
         <span style="font-size: 14pt;">
            <b>@Berkeley</b>
        </span>

        <span style="font-size: 10pt;">
        <dl class="dl-horizontal">
          <dt><b>Undergraduates</b></dt>
            <a href="https://www.linkedin.com/in/xin-qin-4a83b9158/">Xin Qin</a>, now @ USC <br>
            <a href="https://www.linkedin.com/in/hemangjangle/">Hemang Jangle</a> <br>
            <a href="http://www.cs.utexas.edu/~alin/">Angela S. Lin</a>, now @ UT Austin <br>
            <a href="http://young-geng.xyz/">Xinyang Geng</a>, now @ UC Berkeley<br>
            <a href="https://tianheyu927.github.io/">Tianhe Yu</a>, now @ Stanford<br>
            <a href="https://www.linkedin.com/in/candrastefan/">Stefan A. Candra</a>
        </dl>

        <!-- </p> -->
        </span>
        <!-- </p><hr size="2" align="left" noshade=""> -->


        <h2>Teaching </h2>
        <!-- <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017 -->
        <span style="font-size: 12pt;">
        <b>Introduction to Artificial Intelligence (CS 188)</b>, UC Berkeley <br>
        <span style="font-size: 10pt;">
        Graduate Student Instructor (GSI) with Prof. <a href="http://people.eecs.berkeley.edu/~anca/">Anca Dragan</a> <br>
        Spring 2017<br>
        <br>
        <span style="font-size: 12pt;">
        <b>Computer Vision (CS 280)</b>, UC Berkeley <br>
        <span style="font-size: 10pt;">
        Graduate Student Instructor (GSI) with Prof. <a href="http://people.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, Prof. <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a> <br>
        Spring 2016<br>
        <br>
        <span style="font-size: 12pt;">
        <b>Introduction to Circuits (ECE 2100)</b>, Cornell University <br>
        <span style="font-size: 10pt;">
        Teaching Assistant (TA) with Prof. <a href="https://molnargroup.ece.cornell.edu/">Alyosha Molnar</a> <br>
        Spring 2010<br>
        <br>

        <h2>My Name</h2>
        Confused by the contents of this page? Well, you may have been looking for Professor <a href="https://www.cs.sfu.ca/~haoz/" border="0">Richard Zhang</a> or Professor <a href="https://ryz.ece.illinois.edu/" border="0">Richard Zhang</a>. My Chinese name is 章睿嘉.

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75897335-1', 'auto');
  ga('send', 'pageview');
</script>
            
</font></td></tr></tbody></table><iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" input="null" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div></body></html>

